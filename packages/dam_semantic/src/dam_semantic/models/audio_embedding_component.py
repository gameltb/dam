from typing import Any, Dict, Optional, Type, TypedDict

from dam.models.core import BaseComponent
from sqlalchemy import LargeBinary, String
from sqlalchemy.orm import Mapped, mapped_column


class BaseSpecificAudioEmbeddingComponent(BaseComponent):
    """
    Base class for specific audio embedding components.
    Each subclass will correspond to a unique table for a specific audio model/hyperparameter combination.
    """

    __abstract__ = True

    embedding_vector: Mapped[bytes] = mapped_column(LargeBinary, nullable=False)
    model_name: Mapped[str] = mapped_column(String(255), nullable=False)  # To identify the model used
    # Potentially add fields like 'segment_start_time', 'segment_duration' if embedding parts of audio
    # For now, assumes embedding of the whole audio file or a canonical segment.

    def __repr_base__(self) -> str:
        return (
            f"entity_id={self.entity_id}, model_name='{self.model_name}', "
            f"embedding_vector_len={len(self.embedding_vector) if self.embedding_vector else 0} bytes"
        )


# --- Example Specific Audio Embedding Components ---
class AudioEmbeddingVggishDim128Component(BaseSpecificAudioEmbeddingComponent):
    """
    Stores audio embeddings generated by VGGish model (128 dimensions).
    """

    __tablename__ = "component_audio_embedding_vggish_d128"
    # model_name is already a field in the base class, will be set to "vggish"

    def __repr__(self) -> str:
        return f"AudioEmbeddingVggishD128Component(id={self.id}, {super().__repr_base__()})"


class AudioEmbeddingPannsCnn14Dim2048Component(BaseSpecificAudioEmbeddingComponent):
    """
    Stores audio embeddings generated by PANNs CNN14 model (2048 dimensions).
    """

    __tablename__ = "component_audio_embedding_panns_cnn14_d2048"
    # model_name is already a field in the base class, will be set to "panns_cnn14"

    def __repr__(self) -> str:
        return f"AudioEmbeddingPannsCnn14D2048Component(id={self.id}, {super().__repr_base__()})"


# --- Registry for Audio Embedding Models ---
AudioModelHyperparameters = Dict[str, Any]


class AudioEmbeddingModelInfo(TypedDict):
    model_class: Type[BaseSpecificAudioEmbeddingComponent]
    default_params: AudioModelHyperparameters
    # Potentially add loader function or library info here


AUDIO_EMBEDDING_MODEL_REGISTRY: Dict[str, AudioEmbeddingModelInfo] = {
    "vggish": AudioEmbeddingModelInfo(
        model_class=AudioEmbeddingVggishDim128Component,
        default_params={"dimensions": 128},
    ),
    "panns_cnn14": AudioEmbeddingModelInfo(
        model_class=AudioEmbeddingPannsCnn14Dim2048Component,
        default_params={"dimensions": 2048},
    ),
}


def get_audio_embedding_component_class(
    model_name: str, params: Optional[AudioModelHyperparameters] = None
) -> Optional[Type[BaseSpecificAudioEmbeddingComponent]]:
    """
    Retrieves the specific audio embedding component class based on model name.
    Params matching might be added later if needed.
    """
    registry_entry = AUDIO_EMBEDDING_MODEL_REGISTRY.get(model_name)
    if registry_entry:
        return registry_entry["model_class"]
    return None


__all__ = [
    "BaseSpecificAudioEmbeddingComponent",
    "AudioEmbeddingVggishDim128Component",
    "AudioEmbeddingPannsCnn14Dim2048Component",
    "AUDIO_EMBEDDING_MODEL_REGISTRY",
    "get_audio_embedding_component_class",
    "AudioModelHyperparameters",
    "AudioEmbeddingModelInfo",
]
