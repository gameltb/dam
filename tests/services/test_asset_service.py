from pathlib import Path

import pytest
from sqlalchemy import select
from sqlalchemy.orm import Session

from dam.models import (
    ImagePerceptualAHashComponent,
    ImagePerceptualDHashComponent,
    ImagePerceptualPHashComponent,
)
from dam.services import asset_service, file_operations

# Use fixtures from conftest.py for db_session
# We also need sample image paths, can reuse fixtures from test_file_operations or define new ones.


@pytest.fixture(scope="module")
def module_db_engine():
    """Creates an in-memory SQLite engine for the test module."""
    # Using a distinct engine for this module to avoid conflicts if other modules also use create_all
    # Alternatively, ensure conftest.py's engine is used and tables are managed carefully.
    # For simplicity, using the engine from dam.core.database which should be configured for tests.
    # Assuming dam.core.database.settings.DATABASE_URL is set to an in-memory DB for tests.
    # If not, this needs adjustment.
    # Let's use the conftest.py engine and session management.
    # This means we need to ensure conftest.py is set up or its fixtures are accessible.
    # The conftest.py from previous steps should be available.
    pass  # Rely on conftest.py's engine fixture


@pytest.fixture
def sample_image_a(tmp_path: Path) -> Path:
    img_a_b64 = "iVBORw0KGgoAAAANSUhEUgAAAAIAAAABCAYAAAD0In+KAAAAEUlEQVR42mNkgIL/DAwM/wUADgAB/vA/cQAAAABJRU5ErkJggg=="
    file_path = tmp_path / "sample_A.png"
    import base64

    file_path.write_bytes(base64.b64decode(img_a_b64))
    return file_path


@pytest.fixture
def non_image_file(tmp_path: Path) -> Path:
    file_path = tmp_path / "sample.txt"
    file_path.write_text("This is a test text file.")
    return file_path


def test_add_image_asset_creates_perceptual_hashes(db_session: Session, sample_image_a: Path):
    """Test adding an image asset creates ImagePerceptualHashComponents."""
    # Ensure ImageHash and Pillow are available for this test
    try:
        import imagehash  # noqa: F401
        from PIL import Image  # noqa: F401
    except ImportError:
        pytest.skip("ImageHash or Pillow not installed, skipping perceptual hash integration test.")

    original_filename, size_bytes, mime_type = file_operations.get_file_properties(sample_image_a)
    content_hash = file_operations.calculate_sha256(sample_image_a)

    entity, created_new = asset_service.add_asset_file(
        session=db_session,
        filepath_on_disk=sample_image_a,
        original_filename=original_filename,
        mime_type=mime_type,  # Should be 'image/png'
        size_bytes=size_bytes,
        content_hash=content_hash,
    )
    db_session.commit()

    assert created_new is True
    assert entity.id is not None

    # Verify perceptual hashes
    phash_stmt = select(ImagePerceptualPHashComponent).where(ImagePerceptualPHashComponent.entity_id == entity.id)
    phashes = db_session.execute(phash_stmt).scalars().all()
    ahash_stmt = select(ImagePerceptualAHashComponent).where(ImagePerceptualAHashComponent.entity_id == entity.id)
    ahashes = db_session.execute(ahash_stmt).scalars().all()
    dhash_stmt = select(ImagePerceptualDHashComponent).where(ImagePerceptualDHashComponent.entity_id == entity.id)
    dhashes = db_session.execute(dhash_stmt).scalars().all()

    total_hashes = len(phashes) + len(ahashes) + len(dhashes)
    # For very small/simple images, some hash types might not be generated by imagehash
    # So we check if at least one type was generated.
    assert total_hashes > 0

    # Check properties of found hashes
    for comp_list in [phashes, ahashes, dhashes]:
        for comp in comp_list:
            assert comp.hash_value is not None
            assert len(comp.hash_value) > 0


def test_add_non_image_asset_no_perceptual_hashes(db_session: Session, non_image_file: Path):
    """Test adding a non-image asset does not create ImagePerceptualHashComponents."""
    original_filename, size_bytes, mime_type = file_operations.get_file_properties(non_image_file)
    content_hash = file_operations.calculate_sha256(non_image_file)

    entity, created_new = asset_service.add_asset_file(
        session=db_session,
        filepath_on_disk=non_image_file,
        original_filename=original_filename,
        mime_type=mime_type,  # Should be 'text/plain' or 'application/octet-stream'
        size_bytes=size_bytes,
        content_hash=content_hash,
    )
    db_session.commit()

    assert created_new is True
    assert entity.id is not None

    # Verify no perceptual hashes
    phash_stmt = select(ImagePerceptualPHashComponent).where(ImagePerceptualPHashComponent.entity_id == entity.id)
    assert len(db_session.execute(phash_stmt).scalars().all()) == 0
    ahash_stmt = select(ImagePerceptualAHashComponent).where(ImagePerceptualAHashComponent.entity_id == entity.id)
    assert len(db_session.execute(ahash_stmt).scalars().all()) == 0
    dhash_stmt = select(ImagePerceptualDHashComponent).where(ImagePerceptualDHashComponent.entity_id == entity.id)
    assert len(db_session.execute(dhash_stmt).scalars().all()) == 0


def test_add_existing_image_content_adds_missing_perceptual_hashes(
    db_session: Session, sample_image_a: Path, tmp_path: Path
):
    """
    Test that if an image is added (content exists), and it's missing some perceptual hashes,
    they get added on a subsequent add_asset_file call for that content.
    """
    try:
        import imagehash  # noqa: F401
        from PIL import Image  # noqa: F401
    except ImportError:
        pytest.skip("ImageHash or Pillow not installed, skipping advanced perceptual hash test.")

    # --- First add ---
    props1 = file_operations.get_file_properties(sample_image_a)
    chash1 = file_operations.calculate_sha256(sample_image_a)
    entity1, _ = asset_service.add_asset_file(db_session, sample_image_a, props1[0], props1[2], props1[1], chash1)
    db_session.commit()

    # Verify all 3 perceptual hashes are there initially
    phashes_initial = (
        db_session.execute(
            select(ImagePerceptualPHashComponent).where(ImagePerceptualPHashComponent.entity_id == entity1.id)
        )
        .scalars()
        .all()
    )
    ahashes_initial = (
        db_session.execute(
            select(ImagePerceptualAHashComponent).where(ImagePerceptualAHashComponent.entity_id == entity1.id)
        )
        .scalars()
        .all()
    )
    dhashes_initial = (
        db_session.execute(
            select(ImagePerceptualDHashComponent).where(ImagePerceptualDHashComponent.entity_id == entity1.id)
        )
        .scalars()
        .all()
    )

    # For the test to be meaningful, all hash types should be present initially.
    # The sample image is simple, so it should generate all.
    if not (phashes_initial and ahashes_initial and dhashes_initial):
        msg = (
            "Initial add did not generate all expected hash types (phash, ahash, dhash), "
            "cannot accurately test missing hash addition."
        )
        pytest.skip(msg)

    # --- Simulate missing one hash type (e.g., dhash) ---
    # We know dhashes_initial is not empty from the check above
    dhash_comp_to_delete = dhashes_initial[0]
    db_session.delete(dhash_comp_to_delete)
    db_session.commit()

    # Verify it's gone
    dhash_del_stmt = select(ImagePerceptualDHashComponent).where(ImagePerceptualDHashComponent.entity_id == entity1.id)
    dhashes_after_delete = db_session.execute(dhash_del_stmt).scalars().all()
    assert len(dhashes_after_delete) == 0

    # --- Second add (same content, different file instance/path to simulate new discovery) ---
    # Create a copy of sample_image_a to simulate a new file with same content
    copy_of_sample_image_a = tmp_path / "sample_A_copy.png"
    import shutil

    shutil.copy2(sample_image_a, copy_of_sample_image_a)

    props2 = file_operations.get_file_properties(copy_of_sample_image_a)
    chash2 = file_operations.calculate_sha256(copy_of_sample_image_a)
    assert chash1 == chash2  # Content hash must be the same

    entity2, created_new2 = asset_service.add_asset_file(
        db_session, copy_of_sample_image_a, props2[0], props2[2], props2[1], chash2
    )
    db_session.commit()

    assert created_new2 is False  # Entity should be existing
    assert entity2.id == entity1.id

    # Verify the 'dhash' is now present again
    phash_final_stmt = select(ImagePerceptualPHashComponent).where(
        ImagePerceptualPHashComponent.entity_id == entity2.id
    )
    phashes_final = db_session.execute(phash_final_stmt).scalars().all()

    ahash_final_stmt = select(ImagePerceptualAHashComponent).where(
        ImagePerceptualAHashComponent.entity_id == entity2.id
    )
    ahashes_final = db_session.execute(ahash_final_stmt).scalars().all()

    dhash_final_stmt = select(ImagePerceptualDHashComponent).where(
        ImagePerceptualDHashComponent.entity_id == entity2.id
    )
    dhashes_final = db_session.execute(dhash_final_stmt).scalars().all()

    assert len(dhashes_final) > 0  # dhash should be re-added
    assert dhashes_final[0].hash_value == dhashes_initial[0].hash_value  # ensure it's the same hash value

    # Ensure other original hashes are still there and unchanged
    assert len(phashes_final) == len(phashes_initial)
    if phashes_initial:  # if it existed before
        assert phashes_final[0].hash_value == phashes_initial[0].hash_value

    assert len(ahashes_final) == len(ahashes_initial)
    if ahashes_initial:  # if it existed before
        assert ahashes_final[0].hash_value == ahashes_initial[0].hash_value
